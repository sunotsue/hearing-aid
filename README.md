# hearing-aid

The goal of this project was to predict an individual's complete audiogram (hearing test results) based on their hearing threshold gain values for 2k, 4k, and 6k. After removing NA's and non-numerical data ("**") and setting categorical data that aren't relevant for the analysis as indices, I trained the dataset with three different models - Neural Network, Multivariate Multiple Linear Regression, and Decision Tree. Using MAE and RMSE as the primary evaluation metrics, I decided to use Neural Network despite the Decision Tree outperforming the other two in RMSE. Although multi output regressors come handy in building multiple models at once, our target variables (and input variables) are significantly correlated with one another and hence better explained through a single model that predicts a vector.

Note that the Jupyter Notebook file includes the full analysis from data cleaning to EDA to model selection and the Python script file only includes the Neural Network pipeline. The HTML, JS, and app.py files were to deploy my model to web with Flask on AWS EC2 Instance, but I ran into the error of not having Flattened the data before entering it into the Dense player which caused a shape misalignment issue for the Form. I decided to submit the scripts as they are to meet the submission deadline :) 
